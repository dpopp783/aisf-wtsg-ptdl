{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b28365e-20a6-4e9d-b320-5042c510cbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops (from -r requirements.txt (line 1))\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting kappamodules (from -r requirements.txt (line 2))\n",
      "  Downloading kappamodules-0.1.112-py3-none-any.whl.metadata (926 bytes)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from kappamodules->-r requirements.txt (line 2)) (2.1.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kappamodules->-r requirements.txt (line 2)) (1.26.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->kappamodules->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->kappamodules->-r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->kappamodules->-r requirements.txt (line 2)) (1.3.0)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kappamodules-0.1.112-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops, kappamodules\n",
      "Successfully installed einops-0.8.0 kappamodules-0.1.112\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import WeakLabeledData\n",
    "\n",
    "try:\n",
    "    import einops\n",
    "except:\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f1bdfd-5709-469e-a155-434824058424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GROUND_TRUTH = False\n",
    "DATASET = 'imagenet'\n",
    "STARTING_EPOCH = 0  # set this value when resuming a paused training run. The code will later load the saved intermediate model, and modify the training loop for the correct number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b535e1-a68b-4bf0-8121-cb8911e52abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DinoClassification(nn.Module):\n",
    "    \"\"\"Add a classification head to an existing DINO model\"\"\"\n",
    "    def __init__(self, original_model, num_classes=10):\n",
    "        super(DinoClassification, self).__init__()\n",
    "        \n",
    "        # copy layers from original model\n",
    "        self.dino = original_model\n",
    "        \n",
    "        # add classification head\n",
    "        self.head = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass input through dino model\n",
    "        x = self.dino(x)\n",
    "\n",
    "        # Extract the class token and pass through the classification head\n",
    "        cls_token = x[:, 0]  # Shape: (batch_size, embed_dim)\n",
    "        x = self.head(cls_token)  # Shape: (batch_size, num_classes)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7350d1-ed1a-4514-8542-fa6755d74d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_dino(num_classes=10, freeze=True):\n",
    "    # DINO, pretrained on ImageNet-1k based on the representations of ViT-L/16\n",
    "    dino = torch.hub.load(\"BenediktAlkin/torchhub-ssl\", \"in1k_dinov2_l16\", trust_repo=True)\n",
    "    \n",
    "    # add classification head\n",
    "    model = DinoClassification(dino, num_classes)\n",
    "    \n",
    "    if freeze:\n",
    "        # freeze layers for finetuning\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze last layer to finetune\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # for param in model.dino.blocks[-1].parameters():\n",
    "        #     param.requires_grad = True\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96705e80-4fb7-4ea6-ba93-01543a9e535b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/BenediktAlkin/torchhub-ssl/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://huggingface.co/BenediktAlkin/DINOv2/resolve/main/in1k_large16.pth\" to /root/.cache/torch/hub/checkpoints/in1k_dinov2_large16.pth\n",
      "100%|██████████| 1.22G/1.22G [00:30<00:00, 42.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = setup_dino(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fa7593-fd6f-4d22-971e-5704540063a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if STARTING_EPOCH > 0:\n",
    "    model.load_state_dict(torch.load(f'models/{DATASET}/dino_{\"gt\" if GROUND_TRUTH else \"wtsg\"}_epoch{STARTING_EPOCH}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92154cfa-4b81-409c-9f7a-5dafc8bad7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = torch.load(f'./data/{DATASET}-split/weak-labeled-half.pth')\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8960ce0-f342-43bf-9c95-21e76a315c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6819bb6-1c3c-4591-8b7c-5a1fe521b324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Loop setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd9e3c8c-f3fd-4047-8e03-1535cfd88d73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] (WTSG): 100%|██████████| 313/313 [18:37<00:00,  3.57s/it, avg_loss=0.0483, cum_loss=1.93e+3]\n",
      "Epoch [2/10] (WTSG): 100%|██████████| 313/313 [19:11<00:00,  3.68s/it, avg_loss=0.0323, cum_loss=1.29e+3]\n",
      "Epoch [7/10] (WTSG): 100%|██████████| 313/313 [18:48<00:00,  3.60s/it, avg_loss=0.0132, cum_loss=529]\n",
      "Epoch [8/10] (WTSG): 100%|██████████| 313/313 [18:12<00:00,  3.49s/it, avg_loss=0.0118, cum_loss=471]\n",
      "Epoch [9/10] (WTSG): 100%|██████████| 313/313 [18:49<00:00,  3.61s/it, avg_loss=0.0105, cum_loss=418]\n",
      "Epoch [10/10] (WTSG): 100%|██████████| 313/313 [18:39<00:00,  3.58s/it, avg_loss=0.00928, cum_loss=371]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "model.train()\n",
    "\n",
    "NUM_EPOCHS = 10  # Fine-tuning for 3 epochs\n",
    "\n",
    "for epoch in range(STARTING_EPOCH,NUM_EPOCHS): # WHEN FINISHING A RUN SET LOWER BOUND\n",
    "    cum_loss = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, leave=True)\n",
    "    progress_bar.set_description(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] ({'GT' if GROUND_TRUTH else 'WTSG'})\")\n",
    "    for idx, (images, true_labels, weak_labels) in enumerate(progress_bar):\n",
    "        images, true_labels, weak_labels = images.to(device), true_labels.to(device), weak_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        if GROUND_TRUTH:\n",
    "            # training step for ground truth model\n",
    "            loss = criterion(outputs, true_labels)\n",
    "        else:\n",
    "            # training step for weak labels model\n",
    "            loss = criterion(outputs, weak_labels)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "        total += len(true_labels)\n",
    "        \n",
    "        avg_loss = cum_loss / total\n",
    "        \n",
    "        # Update the tqdm bar with loss and epoch\n",
    "        progress_bar.set_postfix({\"avg_loss\":avg_loss, \"cum_loss\":cum_loss})\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        if GROUND_TRUTH:\n",
    "            name = f'dino_gt_epoch{epoch+1}.pth'\n",
    "        else:\n",
    "            name = f'dino_wtsg_epoch{epoch+1}.pth'\n",
    "        torch.save(model.state_dict(), f'models/{DATASET}/{name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2ad1bdf-8399-4d05-afbb-1cc63fa3cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the fine-tuned model\n",
    "# if GROUND_TRUTH:\n",
    "#     name = f'dino_gt_epoch10.pth'\n",
    "# else:\n",
    "#     name = f'dino_wtsg_epoch10.pth'\n",
    "# torch.save(model.state_dict(), f'models/{DATASET}/{name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466aba4-df34-439f-baac-6a5cacbe8275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the test data\n",
    "# Define preprocessing transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  # All 3 models expect 224x224 images\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # normalization constants for ImageNet-1k (pre-training data)\n",
    "# ])\n",
    "\n",
    "# test_data = CIFAR100(root='./data', train=False, transform=transform)\n",
    "test_data = torch.load(f'data/{DATASET}-split/test.pth')\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c47e12-76a5-4528-a4c4-9b067ead7d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [04:56<00:00,  3.75s/it, accuracy=72.7, correct=7267, loss=0.0118]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4964\n",
      "Test Accuracy: 72.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Initialize metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation to save memory and computation\n",
    "    progress_bar = tqdm(test_loader, leave=True)\n",
    "    for idx, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device) # send data to gpu\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()  # Accumulate loss\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics for display\n",
    "        avg_loss = test_loss / total\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        # Update the tqdm bar with loss and accuracy\n",
    "        progress_bar.set_postfix(loss=avg_loss, accuracy=accuracy, correct=correct)\n",
    "\n",
    "# Calculate final metrics\n",
    "avg_loss = test_loss / len(test_loader)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c4b5b50-d710-463c-b1cc-43d2e0428b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729668674698795"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(.7267 - .5214) / (.7870 - .5214)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
